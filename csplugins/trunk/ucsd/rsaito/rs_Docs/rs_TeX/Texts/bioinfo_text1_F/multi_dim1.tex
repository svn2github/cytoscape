\chapter{コドンバイアスの解析}

\begin{abstract}

生化学情報にはコドン使用や、時系列および組織別の遺伝子発現量など、様々な
多次元データが存在します。例えばコドンは終止コドンを除くと61種類あります
から、コドン使用は61次元データになりますし、各遺伝子に対して7つの時点で
の発現量を測った場合、その発現データは7次元データになります。

多次元情報は多くの情報を含んでいますが、要素間の関係を多次元情報から直接
理解するのは困難です。人が直感的に理解できるのは、せいぜい3次元まででし
ょう。そこで本章では、コドンバイアスを題材として、多次元データを2次元な
ど低い時限に集約して全体の傾向を把握する方法について説明します。

\end{abstract}


\section{コドンバイアスとは？}

mRNAの情報に基づいてタンパク質が合成されるとき、tRNAという分子がmRNA上の
コドンと呼ばれる3塩基で1組の暗号を読んで、そのコドンに対応するアミノ酸をつ
なげてゆきます(図\ref{codon_transl})。どのコドンがどのアミノ酸をコードするか
ということは全生物でほぼ共通です。

\begin{figure}
\includegraphics[scale=0.45]{Figures_EPS/codon_transl.eps}
\caption{tRNAによるコドンの翻訳}
\label{codon_transl}
\end{figure}

さて、20種類のアミノ酸が61種類のコドンによってコードされるため、あるアミ
ノ酸をコードするコドンは1種類ではない場合が当然あります。例えばバリン(V)
をコードするコドンは、gta, gtc, gtg, gttの4種類です。このように同じアミ
ノ酸をコードするコドンを、同義コドンと呼びます。多くの同義コドンはコドン
の3番目だけが異なっています。

では同義コドンは均等に使われているのでしょうか？答えは否で多くの生物の場
合、同義コドンは均等には使われていないことが知られています。このように同
義コドンの使用の偏りのことを{\bf コドンバイアス}と呼びます。

コドンバイアスを生じさせる主な原因は2つあります
\cite{cbias_mut_trans1,cbias_mut_trans2}。１つはゲノム全体にかかる変異圧
です。GC含量が高い種のゲノムには、GC方向に偏った変異圧が作用し、AT含量が
高い種のゲノムにはAT方向に偏った変異圧が作用していると考えられています
\cite{label_codon_opinion1,label_codon_GC}。すると例えばGC含有量が高い種
の場合、コドンの3番目の塩基はGまたはCになりやすく、これがコドンバイアス
を生じさせる原因の１つとなっています。

もう1つは翻訳効率です。あるコドンを決まったアミノ酸に翻訳可能なtRNAは1
種類とは限りません。すると同義コドンの中でも、対応するtRNAの数が多い
ものを使った方が翻訳効率は上昇します。大腸菌の場合、リボソームタンパク質を
コードするコドンはなるべく多くのtRNAに対応するようにコドンが使われている
ことが知られています。

種の平均的なコドンバイスの情報を利用して外来遺伝子を推測することが可能で
あり、また翻訳効率とコドンバイアスとの関係を利用して、コドンバイアスから逆に
翻訳効率を予測する手法が開発されています\cite{label_CAI}。このようにコド
ンバイアスの解析には様々な応用が考えられます。


\section{コドンバイアスの定量化}

コドンバイアスを定量化する方法はその目的によってもいくつかに分類されますが、
ここでは1つ1つのコドンの偏りの程度を定量化する指標RSCU(Relative Synonymous Codon Usage)を紹介します。
\(X_{ij}\)をアミノ酸\(i\)に対応するコドン\(j\)が使われた回数、\(n_{i}\)
をアミノ酸\(i\)に対応する同義コドン数とします(\(1 \leq n_{i} \leq 6\))。例
えば、\(X_{\rm L\ CUU}\)はL(Leu,ロイシン)をコードするコドンCUUが使われた回数を
表し、またLをコードするコドンは6種類あるので、\(n_{\rm L}=6\)です。
アミノ酸\(i\)に対応するコドンが使われた回数は\(\sum_{j'}X_{ij'}\)です。
もし各同義コドンが均等に使われるとすれば、
\(X_{ij}=\frac{1}{n_{i}}\sum_{j'}X_{ij'}\)となるはずです。ここでアミノ
酸\(i\)に対応するコドン\(j\)のRSCUと呼ばれる指標は以下のように定義されます。

\begin{equation}
\mbox{RSCU}_{ij}=\frac{X_{ij}}{\frac{1}{n_{i}}\sum_{j'}X_{ij'}}
\end{equation}

分母が期待値であり分子が観測値となっているので、RSCUは観測されたコドンの使用回
数が期待されるコドンの使用回数よりどれだけ多いか（少ないか）を表すO/E値
になっていることが分かります。

例えば、Leuに対応する6つのコドンUUA, UUG, CUU, CUC, CUA, CUGの使用回数が
それぞれ12,6,18,9,12,3だったとすると、\({\rm RSCU}_{\rm L\ 
UUA}=1.2, {\rm RSCU}_{\rm L\ UUG}=0.6, {\rm RSCU}_{\rm L\ 
CUU}=1.8, {\rm RSCU}_{\rm L\ CUC}=0.9, {\rm RSCU}_{\rm L\ 
CUA}=1.2, {\rm RSCU}_{\rm L\ CUG}=0.3\)となります。

\begin{table}
\includegraphics[scale=0.45]{Figures_EPS/ecoli_30S_S20_RSCU.eps}
\caption{大腸菌30Sリボソームタンパク質S20のRSCU}
\label{ecoli_30S_S20_RSCU}
\begin{quotation}
アミノ酸の1文字略号を大文字で、そのコドンを小文字で示す。
\end{quotation}
\end{table}

表\ref{ecoli_30S_S20_RSCU}に大腸菌リボソームタンパク質S20の61個のRSCU値
を示します。
このタンパク質に含まれているアミノ酸の数が限られているので、
この表から厳密な議論はできませんが、例えばアミノ酸"T"(スレオニン)をコー
ドするコドンとして"act"だけが使われ、他が全く使われないなど、コドン使用
の偏りが見られます。

コドンの偏り方は生物種によって異なり、また同じ種でも遺伝子によって異なる
ことがあります。ではどのようにすれば同じ偏り方をしているような遺伝子を集
めることができるでしょうか？単に同じ偏り方をしている遺伝子を集めるだけな
ら、クラスタリングアルゴリズムを使うことができます。しかしそれだけではど
の遺伝子がどの遺伝子とどれくらいコドンバイアスが似ているのか、直感的に知
ることができません。もちろん、距離行列を作れば正確にコドンバイアスの似て
いる遺伝子群が分かりますが、遺伝子の数が数百になってくると、とても目で追
う事はできません。

そこでコドンバイアスのような多次元のデータをより低い次元にマップして、コ
ドンバイアスが似ている遺伝子群を俯瞰する方法を紹介します。


\section{主成分分析}

主成分分析の目的は、多次元情報を情報の損失をなるべく抑えて低い次元に移す
ことです\cite{MA_tanoshi}。まずは二次元データの主成分分析について考えてみましょう。図
\ref{PCA0}の二次元座標に１０個の点があり、それらの座標は\(x_{1}\)軸と、\(x_{2}\)
軸により表されています。ここでよく見てみると、この１０個の点に関しては、
\(x_{1}\)軸の値と、\(x_{2}\)軸の値がほぼ同一になっていることに気づきます。実
際に\(x_{2}=x_{1}\)の直線を引いてみると、１０個の点がほぼこの直線上に乗
ることが分かります。そこで１０個の点がこの直線に乗っていると考えて、
\(x_{2}=x_{1}\)を新しい軸とすれば、二次元の情報を一次元に圧縮できたこと
になります。

\begin{figure}
\includegraphics[scale=0.5]{Figures_EPS/PCA0.eps}
\caption{二次元から一次元へ}
\label{PCA0}
\begin{quotation}
\(x_{1}\)と\(x_{2}\)軸からなる座標上には10個の点と、直線\(x_{2}=x_{1}\)を描いた。
右下の表に10個の点の正確な位置を記した。
\end{quotation}
\end{figure}

図\ref{PCA1}に主成分分析の原理を示します。与えられた複数の点の重心を回転
部分として軸を回転させます。そして各点から軸に対して垂線を下ろし、その垂線
の長さの自乗の合計が最小になるところに軸を決定します。

\begin{figure}
\includegraphics[scale=0.5]{Figures_EPS/PCA1.eps}
\caption{主成分分析の原理}
\label{PCA1}
\end{figure}

\begin{figure}
\includegraphics[scale=0.4]{Figures_EPS/PCA1_2.eps}
\caption{軸の設定}
\label{PCA1_2}
\end{figure}

ではそのような軸をどのように定めればよいか、考えていきましょう。今、図
\ref{PCA1_2}に示すように、二次元平面上に軸\(x_{1}\)と\(x_{2}\)があり、点
P\((x_{1},x_{2})\)のような点が複数存在すると考えます。問題は原点Oを通る
軸\(z_{1}\)をうまく回転させて点Pからの垂線PQの長さの自乗\(|\overline{\rm 
PQ}|^{2}\)を最小にすることです。ここで三平方の定理より、\(|\overrightarrow{\rm 
OQ}|^{2} + |\overline{\rm PQ}|^{2} = |\overrightarrow{\rm OP}|^{2}\)であり、ま
た軸を回転させても\(|\overrightarrow{\rm OP}|^{2}\)が一定のため、\(|\overline{\rm PQ}|^{2}\)を
最小にすることは、\(|\overrightarrow{\rm OQ}|^{2}\)を最大にすることと同じです。
今、\(\overrightarrow{\rm OQ}\)と同じ方法を向いている単位ベクトルを
\(\overrightarrow{\rm OR}\)とし、Rの座標を\((l_{1},l_{2})\)とします。
\(|\overrightarrow{\rm OQ}|=\overrightarrow{\rm OP} \cdot \overrightarrow{\rm 
OR}\)であり、\(|\overrightarrow{\rm OR}|\)=1となるので、\(|\overrightarrow{\rm 
OQ}|^{2}=(l_{1}x_{1} + l_{2}x_{2})^{2}\)となります。実際には複数の点につ
いての合計を算出することになるので、1つ目の点、２つ目の点、...をそれぞれ
\((x_{11},x_{21}),(x_{12},x_{22}), \cdots\)として、
\(\sum_{i}(l_{1}x_{1i}+l_{2}x_{2i})^{2}\)が最大になるように
\(l_{1},l_{2}\)を決めればよいことになります。但しここで\(|\overrightarrow{\rm OR}|\)=1
より、\(l_{1}^{2}+l_{2}^{2}=1\)という制約がつきます。従ってラグランジュ
の未定乗数法(\ref{lagrange}参照)を用い、\(\lambda\)を定数として、

\begin{equation}
g(l_{1},l_{2})=\sum(l_{1}x_{1i}+l_{2}x_{2i})^{2}-\lambda(l_{1}^{2}+l_{2}^{2}-1)
\label{PCA_start_eq}
\end{equation}

\noindent
を最大にすればよいことになります。そのためには式\ref{PCA_start_eq}を
\(l_{1}\)および\(l_{2}\)で偏微分して、

\begin{equation}
\frac{\partial g}{\partial l_{1}}
=\sum_{i}2(l_{1}x_{1i}+l_{2}x_{2i})x_{1i}-2\lambda l_{1}=0
\label{eqlag1}
\end{equation}
\begin{equation}
\frac{\partial g}{\partial l_{2}}
=\sum_{i}2(l_{1}x_{1i}+l_{2}x_{2i})x_{2i}-2\lambda l_{2}=0
\label{eqlag2}
\end{equation}

\noindent
を解きます。軸\(x_{1}\)の値の分散は
\(s_{11}=\frac{1}{m}\sum_{i=1}^{m}(x_{1i}-\overline{x_{1}})^{2}\)であり、
軸\(x_{2}\)の値の分散は
\(s_{22}=\frac{1}{m}\sum_{i=1}^{m}(x_{2i}-\overline{x_{2}})^{2}\)となります。
但し\(\overline{x_{1}},\overline{x_{2}}\)はそれぞれ軸\(x_{1}\)の値の平均および
軸\(x_{2}\)の値の平均です。
また軸\(x_{1}\)と軸\(x_{2}\)の値の共分散は、
\(s_{12}=s_{21}=\frac{1}{m}\sum_{i=1}^{n}(x_{1i}-\overline{x_{1}})(x_{2i}
-\overline{x_{2}})\)です。
対象となる\(m\)個の点の重心がちょうど原点になるようにしておけば、
\(\overline{x_{1}}=0,\overline{x_{2}}=0\)となります。すると式\ref{eqlag1}、
\ref{eqlag2}は

\begin{displaymath}
\frac{1}{m}\left(
 \begin{array}{cc}
 s_{11}        & s_{21} \\
 s_{12}        & s_{22} \\
 \end{array}
\right)
\left(
 \begin{array}{c}
 l_{1} \\
 l_{2} \\
 \end{array}
\right)=
\lambda
\left(
 \begin{array}{c}
 l_{1} \\
 l_{2} \\
 \end{array}
\right)
\end{displaymath}

\noindent
と書き表すことができます。\(s_{ij}\)を\(m\)倍したものを改めて\(s_{ij}\)
に定義し直せば、

\begin{equation}
\left(
 \begin{array}{cc}
 s_{11}        & s_{21} \\
 s_{12}        & s_{22} \\
 \end{array}
\right)
\left(
 \begin{array}{c}
 l_{1} \\
 l_{2} \\
 \end{array}
\right)=
\lambda
\left(
 \begin{array}{c}
 l_{1} \\
 l_{2} \\
 \end{array}
\right)
\label{eq_mvar1}
\end{equation}

\noindent
とより単純な形になります。ここで

\begin{displaymath}
X=\left(
 \begin{array}{cccc}
 x_{11} & x_{21} \\
 x_{12} & x_{22} \\
 \vdots & \vdots \\ 
 x_{1m} & x_{2m} \\
 \end{array}
\right),
L=\left(
 \begin{array}{c}
 l_{1} \\
 l_{2} \\
 \end{array}
\right)
\end{displaymath}

\noindent
とおけば式\ref{eq_mvar1}は

\begin{equation}
X^{t}XL=\lambda L
\label{eq_mvar2}
\end{equation}

\noindent
と書き直すことができます。\ref{eq_mvar2}の解となる\(\lambda\)を\(X^{t}X\)
の固有値、\(L\)を固有ベクトルと呼びます\cite{linear_alge1}。

さて我々が知りたいのは、各点\((x_{1},x_{2})\)が\(z_{1}\)軸上のどの位置に
対応するかということです。\(i\)番目の点の\(z_{1}\)軸上の座標\(z_{1i}\)は
\(|\overrightarrow{\rm OQ}|=\overrightarrow{\rm OP} \cdot \overrightarrow{\rm 
OR}\)より、以下の式により求めることができます。

\(z_{1i}=l_{1}x_{1i} + l_{2}x_{2i} =
 (x_{1i} \ \ x_{2i})
 \left(
 \begin{array}{c}
 l_{1} \\
 l_{2} \\
 \end{array}
 \right)
\)

ところで式\ref{eq_mvar2}の解は１つとは限りません。\(L\)の解\footnote{互
いに線形独立な解}は最大で２つ考えられ、それに対応する\(\lambda\)も２つと
なります。そこで\(L\)の２つの解を\(L_{1}=(l_{11},l_{21})^{t}\)、
\(L_{2}=(l_{12},l_{22})^{t}\)、対応する\(\lambda\)の値を
\(\lambda_{1},\lambda_{2}\)としましょう。どちらがより\(|\overrightarrow{\rm 
OQ}|^{2}\)を大きくするでしょうか？\(|\overrightarrow{\rm OQ}|^{2}\)は、

\begin{displaymath}
|\overrightarrow{\rm OQ}|^{2}=\sum_{i}(l_{1}x_{1i}+l_{2}x_{2i})^{2}
=l_{1}^{2}\sum_{i} x_{1i}^{2} + 2l_{1}l_{2}\sum_{i} x_{1i}x_{2i} + l_{2}^{2}\sum_{i} x_{2i}^{2}
\end{displaymath}

\noindent
と表すことができますが、ここで先ほどと同じように、\(s_{11}=\sum_{i} 
x_{1i}^{2}\)、\(s_{22}=\sum_{i} x_{2i}^{2}\)を使うと、

\begin{displaymath}
|\overrightarrow{\rm OQ}|^{2}=l_{1}^{2}s_{11}+2l_{1}l_{2}s_{12}+l_{2}^{2}s_{22}
=l_{1}(l_{1}s_{11}+l_{2}s_{12}) + l_{2}(l_{1}s_{12} + l_{2}s_{22})
\end{displaymath}

\noindent
となります。さらに式\ref{eq_mvar1}を使うと\(|\overrightarrow{\rm OQ}|^{2}\)は、

\begin{displaymath}
|\overrightarrow{\rm OQ}|^{2}=l_{1}\cdot \lambda l_{1} + l_{2}\cdot \lambda l_{2} = \lambda (l_{1}^{2} + l_{2}^{2}) = \lambda
\end{displaymath}

\noindent
より\(|\overrightarrow{\rm OQ}|^{2} = \lambda\)となるので、大きい方の\(\lambda\)
を用いた方が\(|\overrightarrow{\rm OQ}|^{2} = \lambda\)は大きくなります。

\(\lambda_{1} \geq \lambda_{2}\)として、式\ref{eq_mvar2}は以下のように表
現することができます。

\begin{displaymath}
X^{t}X(L_{1} L_{2}) = (L_{1} L_{2})
\left(
 \begin{array}{cc}
 \lambda_{1} & 0\\
 0           & \lambda_{2} \\
 \end{array}
\right)
\end{displaymath}

各点の新しい軸上での座標は、

\begin{displaymath}
X(L_{1},L_{2})=\left(
\begin{array}{cc}
x_{11} & x_{21} \\
x_{12} & x_{22} \\
\vdots & \vdots \\
x_{1m} & x_{2m} \\
\end{array}
\right)
\left(
\begin{array}{cc}
l_{11} & l_{12} \\
l_{21} & l_{22} \\
\end{array}
\right)
\end{displaymath}

\begin{displaymath}
=
\left(
\begin{array}{cc}
l_{11}x_{11}+l_{21}x_{21} & l_{12}x_{11} + l_{22}x_{21} \\
l_{11}x_{12}+l_{21}x_{22} & l_{12}x_{12} + l_{22}x_{22} \\
\vdots & \vdots\\
l_{11}x_{1m}+l_{21}x_{2m} & l_{12}x_{1m} + l_{22}x_{2m} \\
\end{array}
\right)
\end{displaymath}

\noindent
となります。二次元データを一次元にマッピングしたい場合は、この行列の一列
目を抽出すればいいことになります。

次にこれを\(n\)次元データに拡張してみましょう。
今、\(m\)個の\(n\)次元データ\(f_{1},f_{2},\cdots,f_{m}\)を以下のように行列\(F\)を用いて表します。

\begin{displaymath}
F=
 \left(
 \begin{array}{c}
 f_{1} \\
 f_{2} \\
 \vdots \\
 f_{m-1} \\
 f_{m}\\
 \end{array}
 \right)
=\left(
 \begin{array}{ccccc}
 f_{11}        & f_{12} & \ldots & f_{1\cdot n-1}   & f_{1n} \\
 f_{21}        & f_{22} &        &                  & f_{2n} \\
 \vdots        &        & \ddots &                  &        \\
 f_{m-1\cdot1} &        &        & f_{m-1\cdot n-1} & f_{m-1\cdot n} \\
 f_{m1}        &        &        & f_{m\cdot n-1} & f_{mn} \\
 \end{array}
\right)
\end{displaymath}

\noindent
但し\(f_{ij}\)は\(i\)番目のデータの\(j\)次元目の値を表します。次に各列の
平均を以下の式のように計算します。

\begin{displaymath}
\overline{f_{\cdot j}}=\frac{1}{m}\sum_{k=1}^{m}f_{kj}
\end{displaymath}

次に元の行列\(F\)から各列の平均を計算した行列\(\overline{F}\)を引き、\(F_{c}\)とします。

\begin{displaymath}
F_{c} = F - \overline{F}
= F -
 \left(
 \begin{array}{ccccc}
 \overline{f_{\cdot 1}} & \overline{f_{\cdot 2}} & \cdots & \overline{f_{\cdot n - 1}} & \overline{f_{\cdot n}} \\
 \overline{f_{\cdot 1}} & \overline{f_{\cdot 2}} & \cdots & \overline{f_{\cdot n - 1}} & \overline{f_{\cdot n}} \\
 \vdots                 &                        &        &                            &                        \\
 \overline{f_{\cdot 1}} & \overline{f_{\cdot 2}} & \cdots & \overline{f_{\cdot n - 1}} & \overline{f_{\cdot n}} \\
 \overline{f_{\cdot 1}} & \overline{f_{\cdot 2}} & \cdots & \overline{f_{\cdot n - 1}} & \overline{f_{\cdot n}} \\
 \end{array}
 \right)
\end{displaymath}

さて、\(l_{1}\)列目と\(l_{2}\)列目の間の分散(\(l_{1}=l_{2}\)のとき)および共分散
(\(l_{1} \ne l_{2}\)のとき)を\(s_{l_{1}l_{2}}\)で表すと、

\begin{displaymath}
s_{l_{1}l_{2}}=\frac{1}{m}\sum_{k=1}^{m}
(f_{kl_{1}}-\overline{f_{\cdot l_{1}}})(f_{kl_{2}}-\overline{f_{\cdot l_{2}}})
\end{displaymath}

\noindent
となるので、

\begin{displaymath}
F_{c}^{t}F_{c}
=m\left(
 \begin{array}{ccccc}
 s_{11}        & s_{12} & \ldots & s_{1\cdot n-1}   & s_{1n} \\
 s_{21}        & s_{22} &        &                  & s_{2n} \\
 \vdots        &        & \ddots &                  &        \\
 s_{n-1\cdot1} &        &        & s_{n-1\cdot n-1} & s_{n-1\cdot n} \\
 s_{n1}        &        &        & s_{n\cdot n-1} & s_{nn} \\
 \end{array}
\right)
\end{displaymath}

\noindent
が成立します。さて、

\begin{displaymath}
F_{c}^{t}F_{c}p_{i}=\lambda_{i}p_{i}, i=1,2,\cdots,n
\end{displaymath}

\noindent
を満たすような\(n\)次元ベクトル\(p_{i}\)(固有ベクトル)およびそれに対応す
る\(\lambda_{i}\)(固有値)を求めると\(\lambda_{i} \geq \lambda_{i+1}, 1 
\leq i < n\)として、

\begin{displaymath}
F_{c}^{t}F_{c}=P\Lambda P^{-1}=(p_{1},p_{2}, \cdots, p_{n-1}, p_{n})\Lambda
(p_{1},p_{2}, \cdots, p_{n-1}, p_{n})^{t}
\end{displaymath}

\begin{displaymath}
=\left(
 \begin{array}{cccc}
 p_{11} & p_{21} & \ldots & p_{n1} \\
 p_{12} & p_{22} &        & p_{n2} \\
 \vdots &        & \ddots &        \\
 p_{1n} &        &        & p_{nn} \\
 \end{array}
\right)
\left(
 \begin{array}{cccc}
 \lambda_{1} & 0           & \cdots & 0           \\
 0           & \lambda_{2} &        &             \\
 \vdots      &             & \ddots &             \\
 0           &             &        & \lambda_{n} \\
 \end{array}
\right)
\left(
 \begin{array}{cccc}
 p_{11} & p_{12} & \ldots & p_{1n} \\
 p_{21} & p_{22} &        & p_{2n} \\
 \vdots &        & \ddots &        \\
 p_{n1} &        &        & p_{nn} \\
 \end{array}
\right)
\end{displaymath}


\noindent
のように間に対角行列を作ることができます。

データ\(f_{1},f_{2},\cdots,f_{m}\)の新しい座標
\(z_{1},z_{2},\cdots,z_{m}\)は以下のように表すことができます。

\begin{displaymath}
Z=\left(
\begin{array}{c}
z_{1}\\
z_{2}\\
\vdots \\
z_{m}\\
\end{array}
\right)
=\left(
\begin{array}{cccc}
z_{11} & z_{12} & \cdots & z_{1n} \\
z_{21} & z_{22} &        &        \\
\vdots &        & \ddots &        \\
z_{m1} &        &        & z_{mn} \\
\end{array}
\right)
=F_{c}P=(F-\overline{F})P
\end{displaymath}

従って、\(i\)番目のデータの\(j\)次元目の値は、

\begin{displaymath}
z_{ij}=\sum_{k=1}^{n}(f_{ik}-\overline{f_{\cdot k}})p_{jk}
\end{displaymath}

\noindent
となります。従って\(n\)次元データ\(f_{1},f_{2},\cdots,f_{m}\)を一次元に
マッピングすると、それぞれの一次元座標は\(z_{11},z_{21},\cdots,z_{m1}\)
となります。

\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{Figures_EPS/PCA_3_2.eps}
\end{center}
\caption{主成分分析による３次元データの２次元へのマッピング}
\label{PCA_3_2}
\end{figure}


さてこれまでは、多次元データを一次元にマッピングすることを考えてきました。
しかしその多次元データがある直線上周辺に分布していない場合、一次元へのマ
ッピングは多くの情報を失うことになるため、必ずしも効果的とは言えません。
一方でこれらデータがある平面上に分布している場合、二次元平面へのマッピン
グが効果的と言えます。図\ref{PCA_3_2}では、\(x_{1},x_{2},x_{3}\)の3つの
軸からなる三次元空間内に三次元データに対応する点がプロットされています。
そしてプロットされている点は平面\(z\)上に載っていることが分かります。従
って、三次元上の各点は平面\(z\)上の軸\(z_{1}\)と\(z_{2}\)を使って二次元
データとして表すことができます。通常、\(n\)次元データ
\(f_{1},f_{2},\cdots,f_{m}\)を二次元にマッピングすると、それぞれの二次元
座標は\(Z\)の1次元目と２次元目の値を用いて、
\((z_{11},z_{12}),(z_{21},z_{22}),\cdots,(z_{m1},z_{m2})\)となります。

多次元データをより低い\(k\)次元にマッピングしたときに、どれくらい元のデ
ータを反映しているかの指標として寄与率(累積寄与率)\cite{MA_tanoshi}があり、
\(\frac{\sum_{i=1}^{k}\lambda_{i}}{\sum_{i=1}^{n}\lambda_{i}}\)で定義さ
れます\footnote{
\(\sum_{i=1}^{n}\lambda_{i}=m\sum_{i=1}^{n}s_{ii}\)が成立する。
詳しくは文献\cite{MA_tanoshi,linear_alge1}参照。
}。寄与率が高ければ高いほど、元
のデータの情報の損失を抑えて低次元にマッピングしていることになります。例
えば二次元データを一次元データにマッピングするとき、元の二次元データが完
全に直線上に乗っていれば、寄与率は100\%となります。

\begin{figure}
\underline{\hspace{10cm}}
\begin{verbatim}
PCA.calc <- function(F){
   PCA.res <- prcomp(F)   
   P <- PCA.res$rotation
   Z <- PCA.res$x
   Fc <- t(t(F) - apply(F, 2, mean))
   L <- t(P) %*% t(Fc) %*% Fc %*% P
   return(list(F=F, P=P, Z=Z, Fc=Fc, L=L))
}
\end{verbatim}
\underline{\hspace{10cm}}
\caption{主成分分析を行うR言語のプログラム}
\label{PCA_R}
\begin{quotation}
主成分分析を行いたい行列Fを\verb+PCA.calc(F)+のように関数に渡すと、本文
中で説明している行列\(P\),\(Z\),\(Fc\),\(\Lambda\)をP,Z,Fc,Lのリストとし
て返す。
\end{quotation}
\end{figure}

次元の数が多くなると、これらを手計算で行うのは非常に困難です。そこでR言
語\cite{R_Tips}と呼ばれる統計処理言語を使用すると、これらの行列計算を簡単に行うことが
できます。図\ref{PCA_R}に主成分分析を行うプログラムを掲載しておきます。


\section{コドンバイアスの主成分分析}

\begin{figure}
\includegraphics[scale=0.5]{Figures_EPS/cb_matrix.eps}
\caption{行列\(F\)の構築}
\label{cb_matrix}
\end{figure}

それでは実際にコドンバイアスを主成分分析にかけてみましょう。まず行列\(F\)
を構築しなければなりません。図\ref{cb_matrix}のようにまず各遺伝子の61個
のコドンに対して、RSCU値を求めます。そして行を各遺伝子に、列を各コドンに
対応させるように、RSCU値を表す行列\(F\)を作ります。\(f_{ij}\)は\(i\)番目
の遺伝子の\(j\)番目(\(1 \leq j \leq 61\))のRSCU値になります。

\begin{figure}
\includegraphics[scale=0.5]{Figures_EPS/ec_cb_PCA.eps}
\caption{大腸菌のコドン使用の主成分分析結果}
\label{ec_cb_PCA}
\end{figure}

行列\(F\)に対して\(Z\)を求め、各遺伝子\(i\)の\((z_{i1},z_{i2})\)をプロッ
トしたのが図\ref{ec_cb_PCA}です。各点が各遺伝子のコドン使用を2次元に圧縮
したものを表します。リボソームタンパク質とtRNAシンセターゼの遺伝子は全体
の分布に比べると偏った場所に位置しているのが分かると思います。リボソーム
タンパク質やtRNAシンセターゼはタンパク質の合成に必須であり、多くの細胞で
多量に発現しています。同義コドンのうち、対応するtRNAが細胞内に多く存在す
るものを使用すると、タンパク質の合成効率が良くなることが知られています
\cite{label_CAI}。従って、高発現遺伝子では細胞内に豊富にあるtRNAに対応す
るコドンを特に使用する傾向があると考えられ、これが分布上の偏りとなって現
れていると考えられます。


\section{対応分析}
\label{CA_basic1}

対応分析\footnote{数学的構造は、数量化Ⅲ類と呼ばれる手法と同一。}も主成
分分析と同様、多次元データを低い次元にマッピングします。対応分析ではさら
に行と列を同じ座標にマッピングすることにより、行の項目と列の項目との関係
を把握することができます\cite{CA_intro}。

それでは対応分析ではどのような計算が行われるのか、説明していきます。まず
対象となる全ての要素が分類基準Aにおいて、クラス1～\(m\)のいずれかのクラ
スに属し、また分類基準Bにおいて、クラス1～\(n\)までのいずれかのクラスに
属するとしましょう。コドンバイアスの例ではAは遺伝子、Bはコドンということ
になるでしょう。分類基準Aではクラス\(i\)に属し、分類基準Bではクラス\(j\)
に属する要素の数を\(f_{ij}\)と表します。クラスごとの要素の数は以下のよう
に\(m \times n\)の行列\(F\)でまとめて表すことができます。

\begin{displaymath} F=\left(
 \begin{array}{ccccc}
 f_{11}        & f_{12} & \ldots & f_{1\cdot n-1}   & f_{1n} \\
 f_{21}        & f_{22} &        &                  & f_{2n} \\
 \vdots        &        & \ddots &                  &        \\
 f_{m-1\cdot1} &        &        & f_{m-1\cdot n-1} & f_{m-1\cdot n} \\
 f_{m1}        &        &        & f_{m\cdot n-1} & f_{mn} \\
 \end{array}
\right)
\end{displaymath}

ここで、\(f_{i\cdot}=\sum_{l=1}^{n}f_{il},f_{\cdot j}=\sum_{k=1}^{m}f_{kj}\)として、
行列\(S,C\)を以下のように定義します。

\begin{displaymath}
S^{-\frac{1}{2}}=\left(
 \begin{array}{ccccc}
 \frac{1}{\sqrt{f_{1\cdot}}} & 0                           & \ldots    &    0     & 0 \\
 0                           & \frac{1}{\sqrt{f_{2\cdot}}} &           &          &   \\
 \vdots                      &                             & \ddots    &          &   \\
 0                           &                             &           & \frac{1}{\sqrt{f_{m-1\cdot}}}  &   \\
 0                           &                             &           &          & \frac{1}{\sqrt{f_{m\cdot}}}  \\
 \end{array}
\right)
\end{displaymath}

\begin{displaymath}
C^{-\frac{1}{2}}=\left(
 \begin{array}{ccccc}
 \frac{1}{\sqrt{f_{\cdot1}}} & 0                           & \ldots    &    0     & 0 \\
 0                           & \frac{1}{\sqrt{f_{\cdot2}}} &           &          &   \\
 \vdots                      &                             & \ddots    &          &   \\
 0                           &                             &           & \frac{1}{\sqrt{f_{\cdot n-1}}}  &   \\
 0                           &                             &           &          & \frac{1}{\sqrt{f_{\cdot n}}}  \\
 \end{array}
\right)
\end{displaymath}

また行列\(F,S,C\)を使って行列\(H\)を以下のように定義します。

\begin{equation}
H=S^{-\frac{1}{2}}FC^{-\frac{1}{2}}=\left(
 \begin{array}{ccccc}
 \frac{f_{11}}{\sqrt{f_{1\cdot}f_{\cdot1}}} & \frac{f_{12}}{\sqrt{f_{1\cdot}f_{\cdot2}}} & \ldots    & \ldots                                       & \frac{f_{1n}}{\sqrt{f_{1\cdot}f_{\cdot n}}} \\
 \frac{f_{21}}{\sqrt{f_{2\cdot}f_{\cdot1}}} & \frac{f_{22}}{\sqrt{f_{2\cdot}f_{\cdot2}}} &           &                                              &   \\
 \vdots                                     &                                            & \ddots    &                                              &   \\
 \vdots                                     &                                            &           & \ddots                                       &   \\
 \frac{f_{m1}}{\sqrt{f_{m\cdot}f_{\cdot1}}} &                                            &           &                                              & \frac{f_{mn}}{\sqrt{f_{m\cdot}f_{\cdot n}}} \\
 \end{array}
\right)
\label{H_SFC}
\end{equation}

ここで以下のように式\ref{eq_CA_UV1}、\ref{eq_CA_UV2}、\ref{eq_CA_UV3}を
満たすように行列\(U, V\)を決めます。\(m > n\)、\(d_{ii} \geq d_{i+1\cdot i+1}, 
1 \leq i < m\)として、

\begin{displaymath}
HH^{t}=S^{-\frac{1}{2}}FC^{-1}F^{t}S^{-\frac{1}{2}}=UD^{2}U^{t}=
(u_{1},u_{2}, \cdots, u_{m})D^{2}(u_{1},u_{2}, \cdots, u_{m})^{t}
\end{displaymath}

\begin{equation}
=\left(
 \begin{array}{ccc}
 u_{11}        & \ldots & u_{m1} \\
 \vdots        & \ddots &        \\
 u_{1m}        &        & u_{mm} \\
 \end{array}
\right)
\left(
 \begin{array}{ccc}
 d_{11}^{2} & 0          & \ldots\\
 0          & \ddots     &  \\
 \vdots     &            & d_{mm}^{2} \\
 \end{array}
\right)
\left(
 \begin{array}{ccc}
 u_{11}        & \ldots & u_{1m} \\
 \vdots        & \ddots &        \\
 u_{m1}        &        & u_{mm} \\
 \end{array}
\right)
\label{SVD_eq10}
\end{equation}

\noindent
但し\(u_{i}\)は\(m\)次元ベクトル、\(D\)は\(d_{ii}(1 \leq i \leq m)\)を対
角要素とする\(m \times m\)対角行列で、\(d_{11}=1\)となります
(\ref{ca_corr}参照)。また、

\begin{equation}
u_{i}^{t}u_{i}=\left\{
\begin{array}{ll}
1 & {\rm if}\ i = j\\
0 & {\rm if}\ i \neq j\\
\end{array}
\right.
\label{u_orth}
\end{equation}

\noindent
が成立するようにします。こうすると実際は、\(n < i \leq m\)に対して\(d_{ii} = 0\)と
なるので式\ref{SVD_eq10}は、

\begin{equation} HH^{t}=(u_{1},u_{2}, \cdots, u_{n})\left(
 \begin{array}{ccccc}
 d_{11}^{2} & 0          & \ldots & 0                & 0 \\
 0          & d_{22}^{2} &        &                  &  \\
 \vdots     &            & \ddots &                  &  \\
 0          &            &        & d_{n-1\cdot n-1}^{2} &  \\
 0          &            &        &                  & d_{nn}^{2} \\
 \end{array}
\right)
\left(
 \begin{array}{c}
 u_{1} \\
 u_{2} \\
 \vdots     \\
 u_{n-1}    \\
 u_{n} \\
 \end{array}
\right)
\label{eq_CA_UV1}
\end{equation}

\noindent
と表すことができます。同様にして、

\begin{displaymath}
H^{t}H=VD^{2}V^{t}
\end{displaymath}

\begin{equation}
=(v_{1},v_{2}, \cdots, v_{n})
\left(
 \begin{array}{ccccc}
 d_{11}^{2} & 0          & \ldots & 0                & 0 \\
 0          & d_{22}^{2} &        &                  &  \\
 \vdots     &            & \ddots &                  &  \\
 0          &            &        & d_{n-1\cdot n-1}^{2} &  \\
 0          &            &        &                  & d_{nn}^{2} \\
 \end{array}
\right)
\left(
 \begin{array}{c}
 v_{1} \\
 v_{2} \\
 \vdots     \\
 v_{n-1}    \\
 v_{n} \\
 \end{array}
\right)
\label{eq_CA_UV2}
\end{equation}

\noindent
但し、\(v_{i}\)は\(n\)次元ベクトルです。また

\begin{equation}
v_{i}^{t}v_{i}=\left\{
\begin{array}{ll}
1 & {\rm if}\ i = j\\
0 & {\rm if}\ i \neq j\\
\end{array}
\right.
\label{v_orth}
\end{equation}

\noindent
が成立するようにします。最後に

\begin{equation}
H=UDV^{t}
\label{eq_CA_UV3}
\end{equation}

\noindent
を満たすようにします。ちなみに\(H\)に対してこのような\(U,D,V\)を求めるこ
とを、\(H\)の特異値分解と呼びます\cite{CA_intro}。ここまでできればいよいよ最後の低次元
へのマッピングに入ります。まず\(f_{\cdot \cdot} = 
\sum_{k=1}^{m}\sum_{l=1}^{n}f_{kl}\)として、

\begin{displaymath}
X=(x_{1}, \cdots, x_{n}) = 
\left(
 \begin{array}{ccccc}
 x_{11}        & x_{21} & \ldots & x_{n-1\cdot 1}   & x_{n1} \\
 x_{12}        & x_{22} &        &                  & x_{n2} \\
 \vdots        &        & \ddots &                  &        \\
 x_{1\cdot m-1} &        &        & x_{n-1\cdot m-1} & x_{n\cdot m-1} \\
 x_{1m}        &        &        & x_{n-1\cdot m} & x_{nm} \\
 \end{array}
\right)
\end{displaymath}
\begin{equation}
=\sqrt{f_{\cdot\cdot}}S^{-\frac{1}{2}}U
=\sqrt{f_{\cdot\cdot}}\left(
 \begin{array}{cccc}
 \frac{1}{\sqrt{f_{1\cdot}}} & 0                           & \ldots & 0 \\
 0                           & \frac{1}{\sqrt{f_{2\cdot}}} &        &  \\
 \vdots                      &                             & \ddots &  \\
 0                           &                             &        & \frac{1}{\sqrt{f_{m\cdot}}} \\
 \end{array}
\right)
(u_{1}, \cdots, u_{n})
\label{ca_eq_X}
\end{equation}

\noindent
を求めます。ここで\(x_{k}\)は\(m\)次元ベクトルです。分類基準Aのクラス
\(i\)は\(k\)次元目では\(x_{ki}\)という値を持つことになります。但し、
\(x_{1}=(1,1,1, \cdots, 1)^{t}\)となるので、通常\(x_{1}\)は考慮しません
(\ref{ca_corr}節参照)。つまり例えば、クラス\(i\)を２次元データにマッピン
グすると、\((x_{2i},x_{3i})\)となります。

次に
\begin{displaymath}
Y=(y_{1}, \cdots, y_{n}) = 
\left(
 \begin{array}{ccccc}
 y_{11}        & y_{21} & \ldots & y_{n-1\cdot 1}   & y_{n1} \\
 y_{12}        & y_{22} &        &                  & y_{n2} \\
 \vdots        &        & \ddots &                  &        \\
 y_{1\cdot n-1} &        &        & y_{n-1\cdot n-1} & y_{n\cdot n-1} \\
 y_{1n}        &        &        & y_{n-1\cdot n} & y_{nn} \\
 \end{array}
\right)
\end{displaymath}
\begin{equation}
=\sqrt{f_{\cdot\cdot}}C^{-\frac{1}{2}}V
=\sqrt{f_{\cdot\cdot}}\left(
 \begin{array}{cccc}
 \frac{1}{\sqrt{f_{\cdot1}}} & 0                           & \ldots & 0 \\
 0                           & \frac{1}{\sqrt{f_{\cdot2}}} &        &  \\
 \vdots                      &                             & \ddots &  \\
 0                           &                             &        & \frac{1}{\sqrt{f_{\cdot m}}} \\
 \end{array}
\right)
(v_{1}, \cdots, v_{n})
\label{ca_eq_Y}
\end{equation}

\noindent
を求めます。但し、\(y_{k}\)は\(m\)次元ベクトルです。分類基準Bのクラス
\(j\)は\(k\)次元目では\(y_{kj}\)という値を持つことになります。但し、
\(y_{1}=(1,1,1, \cdots, 1)^{t}\)となるので、通常\(y_{1}\)も考慮しません
(\ref{ca_corr}節参照)。この場合も例えばクラス\(j\)を２次元データにマッピ
ングすると、\((y_{2j},y_{3j})\)となります。

図\ref{CA_R}に対応分析を行うR言語のプログラムを掲載しておきます。

\begin{figure}
\underline{\hspace{10cm}}
\begin{verbatim}
CA.calc <- function(F){
   f.. <- sum(F)
   S <- diag(apply(F, 1, sum))
   C <- diag(apply(F, 2, sum))
   Srsr <- diag(apply(F, 1, sum)^(-1/2))
   Crsr <- diag(apply(F, 2, sum)^(-1/2))
   H <- Srsr %*% F %*% Crsr
   SVD.res <- svd(H)
   U <- SVD.res$u
   D <- diag(SVD.res$d)
   V <- SVD.res$v
   if(U[1,1] < 0){ U <- -U; V <- -V }
   X <- f..^(1/2) * Srsr %*% U
   Y <- f..^(1/2) * Crsr %*% V
   return(list(F=F, H=H, X=X, Y=Y, S=S, C=C, U=U, D=D, V=V))
}
\end{verbatim}
\underline{\hspace{10cm}}
\caption{対応分析を行うR言語のプログラム}
\label{CA_R}
\begin{quotation}
対応分析を行いたい行列Fを\verb+CA.calc(F)+のように関数に渡すと、本文中で説明している行列
\(H\),\(X\),\(Y\),\(S\),\(C\),\(U\),\(D\),\(V\)をH,X,Y,S,C,U,D,Vのリストとして返す。
\end{quotation}
\end{figure}


さて\(x_{k}\)と\(y_{k}\)にはどのような関係があるか調べていきましょう。式
\ref{ca_eq_X}、\ref{ca_eq_Y}を移項して\ref{eq_CA_UV3}に代入すると、

\begin{displaymath}
H=UDV^{t}=\frac{1}{f_{\cdot\cdot}}S^{\frac{1}{2}}XDY^{t}C^{\frac{1}{2}}
\end{displaymath}

\noindent
となります。すると式\ref{H_SFC}より、

\begin{displaymath}
F=S^{\frac{1}{2}}HC^{\frac{1}{2}}=\frac{1}{f_{\cdot\cdot}}SXDY^{t}C
\end{displaymath}

\noindent
が成立します。
\(x_{1}=(1,1,1,\cdots,1)^{t},y_{1}=(1,1,1,\cdots,1)^{t},d_{11}=1\)である
ことに注意すると、\(F\)の各要素\(f_{ij}\)は

\begin{displaymath}
f_{ij}=\frac{f_{i\cdot}f_{\cdot j}}{f_{\cdot \cdot}}\sum_{k=1}^{n}d_{kk}x_{ki}y_{kj}
\end{displaymath}
\begin{equation}
=\frac{f_{i\cdot}f_{\cdot j}}{f_{\cdot \cdot}}
+\frac{f_{i\cdot}f_{\cdot j}}{f_{\cdot \cdot}}d_{22}x_{2i}y_{2j}
+\frac{f_{i\cdot}f_{\cdot j}}{f_{\cdot \cdot}}d_{33}x_{3i}y_{3j}
+\cdots 
+\frac{f_{i\cdot}f_{\cdot j}}{f_{\cdot \cdot}}d_{nn}x_{ni}y_{nj}
\label{ca_expand}
\end{equation}

\noindent
となります。式\ref{ca_expand}は\(d_{kk},x_{ki},y_{kj}\)があれば\(f_{ij}\)
を復元できることを意味します。また\(d_{22}\)や\(d_{33}\)が大きく、これに
比べて\(d_{kk}, k > 3\)が小さければ、
\(x_{2k},x_{3k},y_{2k},y_{3k},d_{22},d_{33}\)だけでも\(f_{ij}\)をほぼ復
元できることを意味します。この場合、情報の欠落を抑えて、各データを２
次元にマッピングできます。

なお、\(d_{kk}\)と\(\chi^{2}\)値の間には、

\begin{displaymath}
f_{\cdot\cdot}\sum_{k=2}^{n}d_{kk}=\chi^{2}
\end{displaymath}

\noindent
の関係が成立しています\cite{CA_intro}。

式\ref{SVD_eq10}を式\ref{ca_eq_X}を用いて変形すると、

\begin{equation}
\frac{1}{\sqrt{f_{\cdot \cdot}}}
S^{-\frac{1}{2}}FC^{-1}F^{t}S^{-\frac{1}{2}}
(S^{\frac{1}{2}}x_{i})
=
\frac{1}{\sqrt{f_{\cdot \cdot}}}
d_{ii}^{2}(S^{\frac{1}{2}}x_{i})
\label{ca_eq_eig1}
\end{equation}

\noindent
となります。

\(M=S^{-\frac{1}{2}}FC^{-1}F^{t}S^{-\frac{1}{2}}\)とおいて、式
\ref{ca_eq_eig1}の両辺を\(\sqrt{f_{ii}}\)倍すれば、

\begin{equation}
MS^{\frac{1}{2}}x_{i}=d^{2}_{ii}S^{\frac{1}{2}}x_{i}
\label{ca_eq_eig2}
\end{equation}

\(M\)が対称行列であることに注意すると、\(x_{k}\)、\(x_{l}\)、
\(d^{2}_{kk}\)、\(d^{2}_{ll}\)に対し、

\begin{equation}
(MS^{\frac{1}{2}}x_{k})^{t}S^{\frac{1}{2}}x_{l}
=(d_{kk}^{2}S^{\frac{1}{2}}x_{k})^{t}S^{\frac{1}{2}}x_{l}
=d_{kk}^{2}(S^{\frac{1}{2}}x_{k})^{t}S^{\frac{1}{2}}x_{l}
\label{ca_eq_eig3}
\end{equation}

\begin{equation}
(S^{\frac{1}{2}}x_{k})^{t}MS^{\frac{1}{2}}x_{l}
=(S^{\frac{1}{2}}x_{k})^{t}d_{ll}^{2}S^{\frac{1}{2}}x_{l}
=d_{ll}^{2}(S^{\frac{1}{2}}x_{k})^{t}S^{\frac{1}{2}}x_{l}
\label{ca_eq_eig4}
\end{equation}

式\ref{ca_eq_eig3}から\ref{ca_eq_eig4}を引いて、

\begin{displaymath}
(d^{2}_{kk}-d^{2}_{ll})(S^{\frac{1}{2}}x_{k})^{t}S^{\frac{1}{2}}x_{l}=0
\end{displaymath}

従って、(\(d^{2}_{kk} \ne d^{2}_{ll}\))なら

\begin{equation}
(S^{\frac{1}{2}}x_{k})^{t}S^{\frac{1}{2}}x_{l}=0
\end{equation}

\noindent
となります。従って\(k > 1\)に対し、

\begin{displaymath}
S^{\frac{1}{2}}x_{1}=(\sqrt{f_{1\cdot}},\cdots,\sqrt{f_{m\cdot}})^{t}, \quad \quad
S^{\frac{1}{2}}x_{k}=(\sqrt{f_{1\cdot}}x_{k1},\cdots,\sqrt{f_{m\cdot}}x_{km})^{t}
\end{displaymath}

\begin{displaymath}
(S^{\frac{1}{2}}x_{1})^{t}S^{\frac{1}{2}}x_{k}=0
\end{displaymath}

\noindent
が成立するので、

\begin{equation}
\sum_{l=1}^{m}f_{l\cdot}x_{kl}=0
\end{equation}

\noindent
となり、結局\(x_{k}\)のベクトルの要素の平均は0となります。
同様のことが\(y\)についても成立します。

次に\(x_{k}\)のベクトルの要素の分散について考えてみると、\(x_{ij}\)の値
を持つ要素が\(f_{ij}\)個あるので、式\ref{u_orth}に注意すると分散は、

\begin{displaymath}
\frac{1}{f_{\cdot\cdot}}x_{i}^{t}Sx_{i}=
\frac{1}{f_{\cdot\cdot}}u_{i}^{t}S^{-\frac{1}{2}}\sqrt{f_{\cdot\cdot}}S\sqrt{f_{\cdot\cdot}}S^{-\frac{1}{2}}u_{i}=1
\end{displaymath}

\noindent
となります。同様の計算が\(y_{k}\)についても成立します。

さらに\ref{ca_corr}節で説明するように、対応分析では\(x_{ik}\)と\(y_{ik}\)
の相関が最大になるようにクラス\(i\)に対する\(x_{ik}\)とクラス\(j\)に対す
る\(y_{ik}\)が決められます。

まとめると、

\begin{itemize}
\item \(x_{k}\)、\(y_{k}\)のベクトルの要素の平均は0になる
\item \(x_{k}\)、\(y_{k}\)のベクトルの要素の分散は1になる
\item \(x_{k}\)、\(y_{k}\)の相関係数がなるべく高くなるように\(x_{k}\)、\(y_{k}\)が決められる
\end{itemize}

\noindent
となります。\(x_{k},y_{k}\)の平均と分散が同じで、相関が高いということは、
\(x_{k}\)と\(y_{k}\)を同一尺度で考えることができることを意味します。そし
て、\(f_{ij}\)が十分多ければ、ある次元\(k\)において、\(x_{ki}\)は
\(y_{kj}\)に近い値をとるようになります。これが対応分析の大きな特徴で、行
と列を同一の尺度にマッピングすることができるのです。


\section{コドンバイアスの対応分析}

\begin{figure}
\includegraphics[scale=0.5]{Figures_EPS/ec_cb_CA.eps}
\caption{大腸菌のコドン使用の対応分析結果}
\label{ec_cb_CA}
\end{figure}

それでは大腸菌のコドン使用を対応分析にかけてみましょう。行列\(F\)の作り
方は主成分分析のときと同じです(図\ref{cb_matrix})。対応分析では、行列
\(F\)に対する\(X\)、\(Y\)が求められます。各遺伝子\(i\)の
\((x_{2i},x_{3i})\)をプロットしたものが図\ref{ec_cb_CA}です。対応分析で
は同時に各コドン\(j\)の\((y_{2j},y_{3j})\)も同じグラフにプロットすること
ができます。ある遺伝子とあるコドンの位置が近い場合、その遺伝子の位置がそ
のコドンの使用頻度に深く関係していることを表します。

図\ref{ec_cb_CA}を見ると、主成分分析を用いたときの結果と同じように、リボ
ソームタンパク、tRNAシンセターゼが全体の分布から偏った位置にあることが分
かります。横軸上ではリボソームタンパク質やtRNAシンセターゼが右の方に偏っ
ています。

そしてコドンとの関係に注目しましょう。アルギニン(R)をコードする6つのコド
ン(aga,agg,cga,cgc,cgg,cgt)の分布を見ると、cgc、cgtは横軸上でリボソーム
タンパク質やtRNAシンセターゼと同様、比較的右に位置しているのが分かります。
一方でaga,aggは左の方に位置しています。この結果より、リボソームタンパク
質やtRNAシンセターゼの分布を右にシフトさせている要因としてcgcやcgtの使用
率が考えられます。実際にリボソームタンパク質やtRNAシンセターゼのコドン使
用を見てみると、アルギニンに対応するコドンとしてcgcやcgtが多く使われ、逆
にagaやaggはほとんど使われていません。

このように対応分析を使うとデータの次元を落とすだけでなく、行と列の関係を
同じ座標上で把握することができます。ただ対応分析は本来クロス集計表に対し
て行われる手法であり、RSCU値などに対して行う場合はその解釈に十分な注意が
必要です\cite{miss_CA}。


\section{自己組織化}

自己組織化(SOM, Self Organization Map)は与えられた多次元のデータ群の1つ1
つを二次元平面など低い次元に対応される手法です\cite{NN_arch,NN_comp}。
平面上では類似したデータ同士が近くに配置されるようにします。このため、デ
ータ間の類似関係が感覚的に大変分かりやすくなります。クラスターというもの
は特に定義されないため、k平均アルゴリズムと異なり、あらかじめクラスター
数を指定する必要がありません。逆に言えば、どのデータがどのクラスターに属
するかということは、通常は不明瞭です。

\begin{figure}
\includegraphics[scale=0.5]{Figures_EPS/SOM_map1.eps}
\caption{各データの二次元平面上へのマッピング}
\label{SOM_map1}
\end{figure}

図\ref{SOM_map1}に自己組織化の基本的な考え方を示します。5次元データが3つ与え
られており、data1とdata2が近い値を示しています。自己組織化は各データを図の
上に示す二次元平面上のどこかにマッピングしますが、このときdata1とdata2をな
るべく近づけるようにマッピングします。以下に各データを効果的にマッピングす
る方法について述べます。

\begin{figure}
\includegraphics[scale=0.5]{Figures_EPS/SOM_structure1.eps}
\caption{自己組織化マップの構造}
\label{SOM_structure1}
\end{figure}

自己組織化では図\ref{SOM_structure1}に示すように、まず出力層と呼ばれる二
次元平面上のノード、入力層と呼ばれるデータ入力用のノード、そして全ての出
力層のノードと全ての入力層のノードをつなぐ結線を定義します。上の層は各デー
タを対応させる平面とし、下の層は各データを直接受け取ります。ここで入力層のノ
ードの数をデータの次元数\(n\)と等しくします。そして入力\(i\)と出力層のノー
ド\(j\)の間の結線に重み\(w_{ij}\)を割り当てます。次に\(n\)次元のデータ群を
時刻\(t \,(=0,1,2,\cdots)\)において１つずつネットワークに提示してゆきます。
そして提示されたデータに基づいて\(w_{ij}\)を更新していきます。同時に各ノード
\(j\)の近傍として定義される領域\(N_{j}\)の範囲も狭めてゆきます。詳細なアルゴ
リズムは以下の通りです。

\(w_{ij}(t) \, (0 \leq i \leq n-1)\)を、時刻\(t\)における入力\(i\)からノ
ード\(j\)への結合の重みとします。また\(N_{j}(t)\)を時刻\(t\)におけるノード
\(j\)の近傍とします。入力データを\(x\)とし、その\(i\)次元目\((0 \leq i 
\leq n - 1)\)の数値を\(x_{i}\)とします。

\begin{figure}
\includegraphics[scale=0.5]{Figures_EPS/SOM_algo2.eps}
\caption{自己組織化アルゴリズム}
\label{SOM_algo1}
\end{figure}

\begin{description}
\item[1.初期化] \(w_{ij}\)を乱数を使って初期化し、\(N_{j}(0)\)を大きく設
定する。
\item[2.入力データの提示] 時刻\(t\)におけるノード\(j\)への入力データ
\(x(t)\)を入力層に提示する(図\ref{SOM_algo1}(a))。
\item[3.距離の計算] 以下の式により、入力データと出力ノード\(j\)との距離
\(d_{j}\)を計算する。
\begin{displaymath}
d_{j} = \sum_{i=0}^{n-1}\left(x_{i}(t)-w_{ij}(t)\right)^{2}
\end{displaymath}

例えば、図\ref{SOM_algo1}(a)の入力データと、一番左の出力ノードとの距離は、
\begin{math}
d_{0} = (x_{0} - w_{0\ 0})^2 + (x_{1} - w_{1\ 0})^2
 = (1.2-0.7)^{2} + (2.3-1.5)^{2} = 0.89
\end{math}
である。これを全ての出力ノードに対して計算する。

\item[4.最小距離の選択] \(d_{j}\)が最小となる出力ノード\(j_{\rm min}\)
を特定する(図\ref{SOM_algo1}(b))。

\item[5.結合荷重の更新] ノード\(j_{\rm min}\)の近傍ノードの集合
\(N_{j_{\rm min}}(t)\)を決定する(図\ref{SOM_algo1}(c))。
そして、ノード\(j_{\rm min}\)と\(N_{j_{\rm min}}(t)\)への結合荷重を
以下の式により更新する。

\begin{displaymath}
w_{ij}(t+1)=w_{ij}(t)+\eta(t)(x_{i}(t)-w_{ij}(t))
\end{displaymath}

ここで、\(j\)は\(N_{j_{\rm min}}(t)\)に含まれる全てのノードである。ま
た\(\eta(t)\)はゲイン\((0<\eta(t)<1)\)と呼ばれる。例えば、\(\eta(t)=0.5\)
のとき、図\ref{SOM_algo1}(d)のように入力ノード0,1から\(j_{\rm min}\)への
重みは、
\(w_{0\ j{\rm min}}=1.1+0.5(1.2-1.1)=1.15\),
\(w_{1\ j{\rm min}}=1.9+0.5(2.3-1.9)=2.1\)
で、それぞれ1.15と2.1になる。

\item[6.反復] \(t\)を増加させて入力データを変え、2.～5.を繰り返す。このとき、\((0<\eta(t)<1)\)
を時間とともに減少させ、重みの更新速度を減少させる。近傍
\(N_{j^{\rm min}}(t)\)も、時間とともにサイズを減少させ、更新される領
域を狭めていく。

\end{description}

以上をごく簡単に要約すると以下のようになります。
\begin{itemize}
\item 学習データに最も近い重みベクトルを持つユニットを探す。
\item このユニットの重みベクトルと入力データの近似度を増加させ、その近傍
のユニットについても、重みと入力との距離を減少させる。
\end{itemize}

最終的に各データは「4.最小距離の選択」に基づき、\(d_{j}\)が最小となる出
力ノードにマッピングされます。

自己組織化を実装すると例えば以下のようなプログラムになります。

\noindent
\underline{\hspace{10cm}}

\begin{verbatim}
/* 
(1) X_LEN, Y_LENはそれぞれマップの横および縦の長さ。
(2) INPUT_DIMは入力データの次元数。
(3) MAX_TIMEは反復回数。
ともに#defineで定義すること。
*/
void self_org(double **data_set, int data_num){ 

  static double w[X_LEN * Y_LEN][INPUT_DIM];
     /* w[j][i], 入力層のノードiから出力層jへの重み */
  static double inp[INPUT_DIM];
     /* 入力データ格納用の配列変数 */
 
  int t; /* 時刻 t */
  int i, j, min_j;
  int k;
  double dist, min;

  static int neighbours[X_LEN * Y_LEN];
     /* 近傍ノード格納用の配列変数 */
  
  int n_neighbours; /* 近傍ノードの数 */

  /* w[][]の初期化 */
  for(j = 0;j < X_LEN * Y_LEN;j ++)
    for(i = 0;i < INPUT_DIM;i ++)
      w[j][i] = 1.0 * (rand() % 100); 


  for(t = 0;t < MAX_TIME;t ++){
    next_data(inp, t, data_set, INPUT_DIM, data_num);
       /* 時刻tにおける次元INPUT_DIMの入力データをinpに入れる */
    min_j = find_winner(inp, w);
       /* 勝者ユニットの決定 */

    n_neighbours = neighbour(min_j, t, neighbours);
       /* 近傍ノードをneighboursに、その数をn_neighboursに入れる */

    /* 勝者ノードを含む近傍ノードに関する重みの更新 */
    for(k = 0;k < n_neighbours;k ++){
      j = neighbours[k];
      for(i = 0;i < INPUT_DIM;i ++){
         w[j][i] += update_rate(t) * (inp[i] - w[j][i]);
      }
    }
   }
}
\end{verbatim}

\noindent
\underline{\hspace{10cm}}

\begin{figure}
\includegraphics[scale=0.45]{Figures_EPS/SOM_simple_res1.eps}
\caption{自己組織化の実行結果の例}
\label{SOM_simple_res11}
\begin{quotation}
20個の三次元データを自己組織化にかけた結果。(a)自己組織化にかけたデータ。
\#はデータ番号。d1, d2, d3はそれぞれの次元の値。(b)自己組織化の結果。数
字はデータ番号を表す。マスの中の数字で、0,15は0番目と15番目のデータが同
じところにマップされたことを表す。
\end{quotation}

\end{figure}

図\ref{SOM_simple_res11}に20個の3次元データをSOMによって2次元平面上にマ
ップした結果を示します。これを見ると例えば、6,8,9,11は近い値を持っており、
これらがマップ上で比較的近い位置に配置されていることが分かります。

\section{コドンバイアスの自己組織化}

では自己組織化を使って、似たようなコドンバイアスを持つ遺伝子を集めてみましょう。
ここでは大腸菌や枯草菌、マイコプラズマ菌など12種類の生物の各遺伝子の
61次元のRSCU値を求め、それらを一緒に自己組織化にかけました。その結果を
図\ref{SOM_codon_bias1}に示します。

\begin{figure}
\includegraphics[scale=0.45]{Figures_EPS/SOM_codon_bias1.eps}
\caption{コドンバイアスの自己組織化}
\label{SOM_codon_bias1}
\begin{quotation}
12種類のバクテリアの遺伝子のコドンバイアスを自己組織化にかけた結果。全遺
伝子の中から、1/10の遺伝子を無作為に抽出したものを使用した。解析した生物種は
以下の通り。
Bbur: {\it Borrelia burgdorferi}, Bsub: {\it Bacillus subtilis},
Buch: {\it Buchnera aphidicola}, Ctra: {\it Chlamydia trachomatis},
Ecoli: {\it Escherichia coli}, Hinf: {\it Haemophilus influenzae},
Hpyl: {\it Helicobacter pylori}, Mgen: {\it Mycoplasma genitalium},
Mtub: {\it Mycobacterium　tuberculosis}, Paer: {\it Pseudomonas aeruginosa},
Tpal: {\it Treponema pallidum}, Vcho: {\it Vibrio cholerae}。
\end{quotation}
\end{figure}

各点は各遺伝子を表し、似たコドンバイアスを持つもの同士が集まるように配置
されているはずです。コドンバイアスは概ね種ごとに集まっていることが分かり
ます。また大腸菌(Ecoli, {\it E. coli})とコレラ菌(Vcho, {\it. V. cholerae})
はコドンバイアスがやや似ていますが、枯草菌(Bsub, {\it B. subtilis})とは
離れているなど、種間のコドンバイアスの類似性なども読み取れます。大腸菌の
遺伝子でも時折離れたところに配置されているものがありますが、これは異なる
コドンバイアスを持つ外来遺伝子の可能性が考えられます。

このように自己組織化を使うことによって、各遺伝子のコドンバイアスの特徴を
二次元平面上にマッピングして分かりやすく比較することが可能になっています。

\begin{practice}
\item \ref{PCA_R}のプログラムをベースにして、コドンバイアスなど多次元デ
ータの主成分分析を行ってみましょう。
\item \ref{CA_R}のプログラムをベースにして、コドンバイアスなど多次元デー
タの対応分析を行ってみましょう。
\item 行列\(F\)の任意の列を\(n\)倍しても、主成分分析の結果は変わらないこ
とを示しましょう。
\item 自己組織化を行うプログラムを完成させましょう。
\end{practice}

